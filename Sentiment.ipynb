{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPviE7gKhvTaxkRuGQsy0AY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jfr11101/MyProjects/blob/main/Sentiment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import numpy as np\n",
        "import nltk, re, string\n",
        "from nltk.corpus import stopwords, twitter_samples\n"
      ],
      "metadata": {
        "id": "-43cM60uOjv2"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download(\"stopwords\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aGAgS2hYi5q9",
        "outputId": "05c070aa-10a2-4f36-ea4a-e6e501ed608b"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def process_tweet(tweet):\n",
        "  stemmer = nltk.PorterStemmer()\n",
        "  stopwords_english = stopwords.words('english')\n",
        "  tweet = re.sub(r'\\$\\w*', '', tweet)\n",
        "  tweet = re.sub(r'^RT[\\s]+', '', tweet)\n",
        "  tweet = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', tweet)\n",
        "  tweet = re.sub(r'#', '', tweet)\n",
        "  tokenizer = nltk.TweetTokenizer(preserve_case=False, strip_handles=True, reduce_len=True)\n",
        "  tweet_tokens = tokenizer.tokenize(tweet)\n",
        "\n",
        "  tweets_clean = []\n",
        "  for word in tweet_tokens:\n",
        "    if (word not in stopwords_english and word not in string.punctuation):\n",
        "      stem_word = stemmer.stem(word)\n",
        "      tweets_clean.append(stem_word)\n",
        "\n",
        "  return tweets_clean\n"
      ],
      "metadata": {
        "id": "AkmMJxsndHrG"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_freqs(tweets, ys):\n",
        "  yslist = np.squeeze(ys).tolist()\n",
        "  freqs = {}\n",
        "  for y, tweet in zip(yslist, tweets):\n",
        "    for word in process_tweet(tweet):\n",
        "      pair = (word, y)\n",
        "      if pair in freqs:\n",
        "        freqs[pair] += 1\n",
        "      else:\n",
        "        freqs[pair] = 1\n",
        "\n",
        "  return freqs"
      ],
      "metadata": {
        "id": "1dxwKV-6fibb"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tweets = ['I am happy', 'I am tricked', 'I am sad', 'I am tired', 'I am tired']\n",
        "ys = [1,0,0,0,0]\n",
        "res = build_freqs(tweets, ys)\n",
        "print(res)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kFehlcR2hgls",
        "outputId": "148d1440-fb0b-4335-f97a-7b6b4e1ea103"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{('happi', 1): 1, ('trick', 0): 1, ('sad', 0): 1, ('tire', 0): 2}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download(\"twitter_samples\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o-1Bvvd4ianA",
        "outputId": "e596ed72-33ca-4486-8d26-115031889cac"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package twitter_samples to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/twitter_samples.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_positive_tweets = twitter_samples.strings('positive_tweets.json')\n",
        "all_negative_tweets = twitter_samples.strings('negative_tweets.json')"
      ],
      "metadata": {
        "id": "BDu9N1MIjKOd"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_pos = all_positive_tweets[:4000]\n",
        "test_pos = all_positive_tweets[4000:]\n",
        "train_neg = all_negative_tweets[:4000]\n",
        "test_neg = all_negative_tweets[4000:]"
      ],
      "metadata": {
        "id": "A9hHJCkNjmYB"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = train_pos + train_neg\n",
        "X_test = test_pos + test_neg"
      ],
      "metadata": {
        "id": "vnpCPF6wj8qU"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = np.append(np.ones((len(train_pos), 1)), np.zeros((len(train_neg), 1)), axis=0)\n",
        "y_test = np.append(np.ones((len(test_pos), 1)), np.zeros((len(test_neg), 1)), axis=0)"
      ],
      "metadata": {
        "id": "n2Wy_xwqkIVP"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "freqs = build_freqs(X_train, y_train)"
      ],
      "metadata": {
        "id": "as-I67C6k2e8"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(freqs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aD1msLuJl3Qd",
        "outputId": "2dfce8f4-963e-42b2-ca7b-69403117f722"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(freqs.keys())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b-4l5w2pmFMD",
        "outputId": "e5fcb9d5-f24d-47f7-ab6c-c40965a8c9b0"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11337"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train[22]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "spUvpwnLmIkZ",
        "outputId": "112e9d71-1478-4920-9e74-374a3107b001"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'@gculloty87 Yeah I suppose she was lol! Chat in a bit just off out x :))'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "process_tweet(X_train[22])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "epsEF8ifmS3C",
        "outputId": "9a9666d1-dd70-4d41-acad-cb09c5424f7b"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['yeah', 'suppos', 'lol', 'chat', 'bit', 'x', ':)']"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid(z):\n",
        "  zz = np.negative(z)\n",
        "  h = 1 / (1+np.exp(zz))\n",
        "\n",
        "  return h"
      ],
      "metadata": {
        "id": "igtycVL-maIF"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gradDiscent(x, y, tetha, alpha, num_items):\n",
        "  m = x.shape[0]\n",
        "  for i in range(0, num_items):\n",
        "    z = np.dot(x, tetha)\n",
        "    h = sigmoid(z)\n",
        "    cost = -1/m*(np.dot(y.transpose(), np.log(h))+np.dot((1-y).transpose(), np.log(1-h)))\n",
        "    tetha = tetha - (alpha/m)*np.dot(x.transpose(), (h-y))\n",
        "\n",
        "  cost = float(cost)\n",
        "  return cost, tetha"
      ],
      "metadata": {
        "id": "7c1ccGFhmu4H"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_features(tweet, freqs):\n",
        "  word_l = process_tweet(tweet)\n",
        "  x = np.zeros((1,3))\n",
        "\n",
        "  x[0,0] = 1\n",
        "  for word in word_l:\n",
        "    x[0,1] += freqs.get((word, 1.0), 0)\n",
        "    x[0,2] += freqs.get((word, 0.0), 0)\n",
        "\n",
        "  assert(x.shape == (1,3))\n",
        "\n",
        "  return x"
      ],
      "metadata": {
        "id": "ImPV7_ZjoOf8"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp = extract_features(X_train[22], freqs)"
      ],
      "metadata": {
        "id": "sCMJvwKbpWE4"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(temp)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y90w3SGQplvR",
        "outputId": "3a3010fb-1dd1-41fe-c37e-d9f58cc73796"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1.000e+00 3.006e+03 1.240e+02]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Training Model"
      ],
      "metadata": {
        "id": "CVkcYMHvp7yC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.zeros((len(X_train), 3))\n",
        "for i in range(len(X_train)):\n",
        "  X[i, :] = extract_features(X_train[22], freqs)\n",
        "\n",
        "Y = y_train\n",
        "J, theta = gradDiscent(X, Y, np.zeros((3,1)), 1e-9, 1500)"
      ],
      "metadata": {
        "id": "5obtJYPCpn06"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_tweet(tweet, freqs, theta):\n",
        "  x = extract_features(tweet, freqs)\n",
        "  y_pred = sigmoid(np.dot(x, theta))\n",
        "\n",
        "  return y_pred"
      ],
      "metadata": {
        "id": "Chr4UmNbqiWC"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_logistic_regression(X_test, y_test, freqs, theta):\n",
        "  y_hat = []\n",
        "  for tweet in X_test:\n",
        "    y_pred = predict_tweet(tweet, freqs, theta)\n",
        "    if y_pred > 0.5:\n",
        "      y_hat.append(1)\n",
        "    else:\n",
        "      y_hat.append(0)\n",
        "\n",
        "  accuracy = (y_hat == np.squeeze(y_test)).sum()/len(X_test)\n",
        "\n",
        "  return accuracy"
      ],
      "metadata": {
        "id": "zVHKaScDrP4G"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tmp_accuacy = test_logistic_regression(X_test, y_test, freqs, theta)\n",
        "print(f'Logistic regression model accuracy: {tmp_accuacy:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KfsAzPzQsKlH",
        "outputId": "53c19dc0-2148-497b-9a9d-3eabba35b528"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic regression model accuracy: 0.5000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def pred(sentence):\n",
        "  yhat = predict_tweet(sentence, freqs, theta)\n",
        "  if yhat >= 0.5:\n",
        "    return 'positive sentiment'\n",
        "  else:\n",
        "    return 'negative seniment'"
      ],
      "metadata": {
        "id": "DdYGGN40sr3b"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_tweet = 'It is so hot today but it is the perfect day for a beach party'\n",
        "res = pred(my_tweet)\n",
        "print(res)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TI2d4y3dteH8",
        "outputId": "a0e7a4b2-b832-4837-a069-de84014d5aa0"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "positive sentiment\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OfSHQVwxtvM0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}